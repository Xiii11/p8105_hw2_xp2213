P8105 Homework 2
================

Name: Xi Peng UNI: xp2213 Date: 10.02.2024

# Problem 1 NYC Transit Data

## Section 1: Data import and cleaning

``` r
NYCtransit_df =
    read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA", "", ".", " ")) |>
  janitor::clean_names() |> 
  unite("routes_served", c(route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11), sep = ",", remove = TRUE, na.rm = TRUE) |> 
  select(line, station_name, station_latitude, station_longitude, routes_served, entry, vending, entrance_type, ada) |>  mutate(
    entry = case_match(
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE
    )
  ) |> 
  relocate(line, station_name, station_latitude, station_longitude, routes_served, entry, vending, entrance_type, ada)
```

The NYC Transit Subway Entrance and Exit dataset contains information
about different subway station’s entrances and exits. Other detailed
information, such as which subway lines stop at which station and their
geographic coordinates, ADA compliance, and detailed information about
the entrances, staffing status, etc.In this step, I cleaned the dataset
by only keep the required variables: line, station_name,
station_latitude, station_longitude, routes_served, entry, vending,
entrance_type, ada. The variable “entry” also converted to logical.
After the cleaning step, the tidy dataset contains 1868 rows and 9
columns.

## Section 2: Distinct stations and ADA compliant Status

``` r
distinct_station =
  NYCtransit_df |> distinct(station_name,line)

ADA_compliant_station =
  NYCtransit_df |> 
  filter(ada == TRUE) |> 
  distinct(station_name,line)

Entry_without_vending = 
  NYCtransit_df |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```

In this dataset, there are 465 distinct stations and 84 stations are ADA
compliant. The proportion of station entrances / exits without vending
allow entrance is 0.3770492.

## Section 3: Distinct station serving the A train and ADA compliance status

``` r
station_served_A = NYCtransit_df |> 
  filter(grepl("A", routes_served)) |> 
  distinct(station_name, line) |> 
  nrow()
  
ADA_compliant_A = NYCtransit_df |> 
  filter(grepl("A", routes_served), ada == TRUE) |> 
  distinct(station_name,line) |> 
  nrow()
```

There are 60 distinct stations serve the A train and 17 of the stations
that serve the A train are ADA compliant.

# Problem 2 Trash Wheel Dataset

## Section 1: Data import & cleaning of the “Mr. Trash Wheel” Sheet

``` r
Mr_wheel = 
  read_excel("Data/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", 
  col_types = c("numeric","text","text","date","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","skip","skip"), skip = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    sports_balls = as.integer(round(sports_balls))
  )
```

In section 1, the original dataset was imported, and the “Mr. Trash
Wheel” sheet was selected. After examining the content of the original
excel dataset, I identified columns labeled “x15” and “x16” as non-data
columns containing only NAs. Therefore, these two columns were removed.
The first row, which contained figure but not actual data, was removed.
Additionally, any rows that did not correspond to a specific dumpster
were filtered out from the dataset. Lastly, the values in the
“sports_balls” column were rounded to nearest integer and converted to
integer variable.

## Section 2: Cleaning of the “Professor Trash Wheel” sheet and “Gwynnda Trash Wheel” sheet

``` r
Prof_wheel = 
  read_excel("Data/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) 

Gwynnda_wheel = 
  read_excel("Data/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel") |> 
  janitor::clean_names() |> 
  drop_na(dumpster)
```

In section 2, similar steps were taken to clean the “Professor Trash
Wheel” sheet and “Gwynnda Trash Wheel” sheet. After importing the
original datasets of these two sheets, their contents were examined to
ensure that no non-data entries were present. Also, any rows that did
not correspond to a specific dumpster were filtered out from the
datasets.

In all three datasets, columns that are not considered non-data but
contain many NA values are kept. Similarly, rows that lack useful
information are also retained as long as they include dumpster-specific
data.

## Section 3: Combination of “Mr. Trash Wheel”, “Professor Trash Wheel”, and “Gwynnda Trash Wheel” sheets

``` r
Mr_wheel_com = Mr_wheel |> mutate(trash_wheel_device = "Mr.", year = as.numeric(year))
Prof_wheel_com = Prof_wheel |> mutate(trash_wheel_device = "Professor")
Gwynnda_wheel_com = Gwynnda_wheel |> mutate(trash_wheel_device = "Gwynnda")

trash_wheel_df = 
  bind_rows(Mr_wheel_com, Prof_wheel_com, Gwynnda_wheel_com) |> 
  janitor::clean_names() |> 
  relocate(trash_wheel_device)

total_weight_trash_Prof = trash_wheel_df |> 
  filter(trash_wheel_device == "Professor") |> 
  drop_na(weight_tons) |> 
  pull(weight_tons) |> 
  sum()

total_cigarette_Gwynnda = trash_wheel_df |> 
  filter(trash_wheel_device == "Gwynnda", month == "June", year == 2022 ) |> 
  drop_na(cigarette_butts) |> 
  pull(cigarette_butts) |> 
  sum()
```

In section 3, the three sheets were combined. The combined dataset
contains a total of 1033 observations and 15 columns. The variables
included in this dataset are: trash_wheel_device, dumpster, month, year,
date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene,
cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls,
homes_powered. An additional column,“trash_wheel_device”, was created
based on the Trash Wheel Website introduction to denote which specific
trash wheel device each observation belongs to. Among these varaibles,
both the “dumpster” variable, which represents the dumpster number, and
the “trash_wheel_device” variable are essential indicators provide
timely and effective access to critical and detailed information for
each observation. Therefore, I relocated the “trash_wheel_device” to a
forward position, specifically to the first column in the dataset, to
facilitate easier information extraction.Based on provided data, the
total weight of trash collected by Professor Trash Wheel was 246.74
tons, and the total number of cigarette butts collected by Gwynnda in
June of 2022 was 1.812^{4}.

# Problem 3 Great British Bake Off Dataset

## Section 1: Data import and cleaning of bakers.csv, bakes.csv, and results.csv

``` r
bakers_df =
  read_csv("data/gbb_datasets/bakers.csv", na = c("NA", "", ".", " ")) |> 
  janitor::clean_names() |> 
  mutate(
    baker_first_name = word(baker_name, 1),
    baker_last_name = word(baker_name, -1)
  ) |> 
  select(-baker_name)

bakes_df =
  read_csv("data/gbb_datasets/bakes.csv", na = c("NA", "", ".", " ")) |> 
  janitor::clean_names() |> 
  rename(baker_first_name = baker)

results_df =
  read_csv("data/gbb_datasets/results.csv", na = c("NA", "", ".", " "), skip = 2) |> 
  janitor::clean_names() |> 
  rename(baker_first_name = baker) |> 
  mutate(
    result = case_match(
      result,
      "IN" ~ "stayed in",
      "OUT" ~ "Eliminated", 
      "STAR BAKER" ~ "Star Baker",
      "WINNER" ~ "Series Winner",
      "Runner-up" ~ "Series Runner up",
      "WD" ~ "withdrew"
    )
  )
```

In this section, the datasets were imported, and I reviewed the contents
of each dataset. I noticed that the bakers’ names in the baker.csv file
were full names, whereas the other datasets only contained the bakers’
first names. To ensure consistency across the datasets, I split the full
names in baker.csv into separate columns as baker_first_name and
baker_last_names. After verifying the consistency between the first_name
and last_name columns and the original baker_name colomn, I removed the
baker_name variable to avoid redundant information. I then labeled the
baker as baker_first_name in all datasets, ensuring consistency.
Additionally, in the results.csv dataset, the first two rows contains
non-data values, so they have been removed.The values of result column
in the results.csv were converted into more descriptive phrases, which
is useful for readability and interpretation.

## Section 2: Check for completeness and correctness across datasets.

``` r
anti_join(bakers_df,bakes_df)
```

    ## Joining with `by = join_by(series, baker_first_name)`

    ## # A tibble: 26 × 6
    ##    series baker_age baker_occupation   hometown baker_first_name baker_last_name
    ##     <dbl>     <dbl> <chr>              <chr>    <chr>            <chr>          
    ##  1     10        28 Geography teacher  Essex    Alice            Fevronia       
    ##  2     10        24 Fashion designer   Halifax  Amelia           LeBruin        
    ##  3      9        30 Banker             London   Antony           Amourdoux      
    ##  4      9        33 Full-time parent   Bristol  Briony           Williams       
    ##  5      9        36 Full-time parent   London   Dan              Beasley-Harling
    ##  6     10        32 Support worker     Rotherh… Dan              Chambers       
    ##  7     10        36 International hea… Whitby   David            Atherton       
    ##  8     10        40 Online project ma… Leeds    Helena           Garcia         
    ##  9     10        20 Student            Durham   Henry            Bird           
    ## 10      9        33 Countryside recre… County … Imelda           McCarron       
    ## # ℹ 16 more rows

``` r
anti_join(bakers_df,results_df)
```

    ## Joining with `by = join_by(series, baker_first_name)`

    ## # A tibble: 1 × 6
    ##   series baker_age baker_occupation hometown    baker_first_name baker_last_name
    ##    <dbl>     <dbl> <chr>            <chr>       <chr>            <chr>          
    ## 1      2        41 Housewife        Ongar, Ess… Jo               Wheatley

``` r
anti_join(results_df,bakes_df)
```

    ## Joining with `by = join_by(series, episode, baker_first_name)`

    ## # A tibble: 596 × 5
    ##    series episode baker_first_name technical result
    ##     <dbl>   <dbl> <chr>                <dbl> <chr> 
    ##  1      1       2 Lea                     NA <NA>  
    ##  2      1       2 Mark                    NA <NA>  
    ##  3      1       3 Annetha                 NA <NA>  
    ##  4      1       3 Lea                     NA <NA>  
    ##  5      1       3 Louise                  NA <NA>  
    ##  6      1       3 Mark                    NA <NA>  
    ##  7      1       4 Annetha                 NA <NA>  
    ##  8      1       4 Jonathan                NA <NA>  
    ##  9      1       4 Lea                     NA <NA>  
    ## 10      1       4 Louise                  NA <NA>  
    ## # ℹ 586 more rows

## Section 3: Combining and organizing data into a meaningful structure

``` r
GBbakeoff_df = results_df |> 
  left_join(bakes_df, by = c("series","baker_first_name","episode")) |> 
  left_join(bakers_df, by = c("baker_first_name","series")) |> 
  relocate(series, episode, baker_first_name, baker_last_name, baker_age, baker_occupation, hometown, technical, result,signature_bake, show_stopper)
```

In this combined dataset, there are 1136 rows and 11 columns.

Exporting the final dataset as a CSV:

``` r
write_csv(GBbakeoff_df,"data/GBbakeoff_df.csv")
```

## Section 4: Table creation for Star baker/Winner of each episode in Seasons 5 through 10

``` r
Star_win_df = 
  GBbakeoff_df |> 
  filter(series >= 5 & series <= 10, result == "Star Baker"| result == "Series Winner") |> 
  select(series, episode, baker_first_name, baker_last_name, baker_age, result, baker_occupation, hometown)

knitr::kable(
  Star_win_df, caption = "Table of Star baker/Winner of each episode in Seasons 5 through 10 "
  )
```

| series | episode | baker_first_name | baker_last_name | baker_age | result | baker_occupation | hometown |
|---:|---:|:---|:---|---:|:---|:---|:---|
| 5 | 1 | Nancy | Birtwhistle | 60 | Star Baker | Retired Practice Manager | Barton-upon-Humber, Lincolnshire |
| 5 | 2 | Richard | Burr | 38 | Star Baker | Builder | Mill Hill, London |
| 5 | 3 | Luis | Troyano | 42 | Star Baker | Graphic Designer | Poynton, Cheshire |
| 5 | 4 | Richard | Burr | 38 | Star Baker | Builder | Mill Hill, London |
| 5 | 5 | Kate | Henry | 41 | Star Baker | Furniture Restorer | Brighton, East Sussex |
| 5 | 6 | Chetna | Makan | 35 | Star Baker | Fashion Designer | Broadstairs, Kent |
| 5 | 7 | Richard | Burr | 38 | Star Baker | Builder | Mill Hill, London |
| 5 | 8 | Richard | Burr | 38 | Star Baker | Builder | Mill Hill, London |
| 5 | 9 | Richard | Burr | 38 | Star Baker | Builder | Mill Hill, London |
| 5 | 10 | Nancy | Birtwhistle | 60 | Series Winner | Retired Practice Manager | Barton-upon-Humber, Lincolnshire |
| 6 | 1 | Marie | Campbell | 66 | Star Baker | Retired | Auchterarder, Perthshire |
| 6 | 2 | Ian | Cumming | 41 | Star Baker | Travel photographer | Great Wilbraham, Cambridgeshire |
| 6 | 3 | Ian | Cumming | 41 | Star Baker | Travel photographer | Great Wilbraham, Cambridgeshire |
| 6 | 4 | Ian | Cumming | 41 | Star Baker | Travel photographer | Great Wilbraham, Cambridgeshire |
| 6 | 5 | Nadiya | Hussain | 30 | Star Baker | Full-time mother | Leeds / Luton |
| 6 | 6 | Mat | Riley | 37 | Star Baker | Fire fighter | London |
| 6 | 7 | Tamal | Ray | 29 | Star Baker | Trainee anaesthetist | Manchester |
| 6 | 8 | Nadiya | Hussain | 30 | Star Baker | Full-time mother | Leeds / Luton |
| 6 | 9 | Nadiya | Hussain | 30 | Star Baker | Full-time mother | Leeds / Luton |
| 6 | 10 | Nadiya | Hussain | 30 | Series Winner | Full-time mother | Leeds / Luton |
| 7 | 1 | Jane | Beedle | 61 | Star Baker | Garden designer | Beckenham |
| 7 | 2 | Candice | Brown | 31 | Star Baker | PE teacher | Barton-Le-Clay, Bedfordshire |
| 7 | 3 | Tom | Gilliford | 26 | Star Baker | Project engagement manager | Rochdale |
| 7 | 4 | Benjamina | Ebuehi | 23 | Star Baker | Teaching assistant | South London |
| 7 | 5 | Candice | Brown | 31 | Star Baker | PE teacher | Barton-Le-Clay, Bedfordshire |
| 7 | 6 | Tom | Gilliford | 26 | Star Baker | Project engagement manager | Rochdale |
| 7 | 7 | Andrew | Smyth | 25 | Star Baker | Aerospace engineer | Derby / Holywood, County Down |
| 7 | 8 | Candice | Brown | 31 | Star Baker | PE teacher | Barton-Le-Clay, Bedfordshire |
| 7 | 9 | Andrew | Smyth | 25 | Star Baker | Aerospace engineer | Derby / Holywood, County Down |
| 7 | 10 | Candice | Brown | 31 | Series Winner | PE teacher | Barton-Le-Clay, Bedfordshire |
| 8 | 1 | Steven | Carter-Bailey | 34 | Star Baker | Marketer | Watford, Hertfordshire |
| 8 | 2 | Steven | Carter-Bailey | 34 | Star Baker | Marketer | Watford, Hertfordshire |
| 8 | 3 | Julia | Chernogorova | 21 | Star Baker | Aviation Broker | Crawley, West Sussex |
| 8 | 4 | Kate | Lyon | 29 | Star Baker | Health and safety inspector | Merseyside |
| 8 | 5 | Sophie | Faldo | 33 | Star Baker | Former army officer and trainee stuntwoman | West Molesey, Surrey |
| 8 | 6 | Liam | Charles | 19 | Star Baker | Student | North London |
| 8 | 7 | Steven | Carter-Bailey | 34 | Star Baker | Marketer | Watford, Hertfordshire |
| 8 | 8 | Stacey | Hart | 42 | Star Baker | Former school teacher | Radlett, Hertfordshire |
| 8 | 9 | Sophie | Faldo | 33 | Star Baker | Former army officer and trainee stuntwoman | West Molesey, Surrey |
| 8 | 10 | Sophie | Faldo | 33 | Series Winner | Former army officer and trainee stuntwoman | West Molesey, Surrey |
| 9 | 1 | Manon | Lagrave | 26 | Star Baker | Software project manager | London |
| 9 | 2 | Rahul | Mandal | 30 | Star Baker | Research scientist | Rotherham |
| 9 | 3 | Rahul | Mandal | 30 | Star Baker | Research scientist | Rotherham |
| 9 | 4 | Dan | Beasley-Harling | 36 | Star Baker | Full-time parent | London |
| 9 | 5 | Kim-Joy | Hewlett | 27 | Star Baker | Mental health specialist | Leeds |
| 9 | 6 | Briony | Williams | 33 | Star Baker | Full-time parent | Bristol |
| 9 | 7 | Kim-Joy | Hewlett | 27 | Star Baker | Mental health specialist | Leeds |
| 9 | 8 | Ruby | Bhogal | 29 | Star Baker | Project manager | London |
| 9 | 9 | Ruby | Bhogal | 29 | Star Baker | Project manager | London |
| 9 | 10 | Rahul | Mandal | 30 | Series Winner | Research scientist | Rotherham |
| 10 | 1 | Michelle | Evans-Fecci | 35 | Star Baker | Print shop administrator | Tenby, Wales |
| 10 | 2 | Alice | Fevronia | 28 | Star Baker | Geography teacher | Essex |
| 10 | 3 | Michael | Chakraverty | 26 | Star Baker | Theatre manager/fitness instructor | Stratford-upon-Avon |
| 10 | 4 | Steph | Blackwell | 28 | Star Baker | Shop assistant | Chester |
| 10 | 5 | Steph | Blackwell | 28 | Star Baker | Shop assistant | Chester |
| 10 | 6 | Steph | Blackwell | 28 | Star Baker | Shop assistant | Chester |
| 10 | 7 | Henry | Bird | 20 | Star Baker | Student | Durham |
| 10 | 8 | Steph | Blackwell | 28 | Star Baker | Shop assistant | Chester |
| 10 | 9 | Alice | Fevronia | 28 | Star Baker | Geography teacher | Essex |
| 10 | 10 | David | Atherton | 36 | Series Winner | International health adviser | Whitby |

Table of Star baker/Winner of each episode in Seasons 5 through 10

In this section, the question asks about the star baker/winner of each
episode in Seasons 5 through 10. I filtered out these persons and formed
a reader-friendly table. The key information, such as the which series
and episode the star baker/winner attend and results for illustrating
they were either star baker or winner, were placed in front. Other
personally relevant information of each participant was placed
afterwards.

According to the table, the first thing I noticed is that Richard Burr
earned “Star Baker” title in five episodes of Series 5. However, despite
his strong performance, Nancy Birtwhistle was the “Series Winner” for
that series, and she also won “Star Baker” once. In Series 6, Nadiya
Hussain won the “Star Baker” title for four time and also earned the
“Series Winner” title. Similarly, in Series 7, Candice Brown won the
most “Star baker” titles and ultimately become the “Series Winner”. In
Series 8, although Steven Carter-Bailey earned the most “Star Baker”
titles, Sophie Faldo was the “Series Winner”. In Series 9, Rahul Mandal
earned the most “Star Baker” titles and won the “Series Winner”. In
Series 10, Steph Blackwell earned the most “Star Baker” titles but David
Atherton was the “Series Winner”.

In conclusion, based on the patterns observed in this table, it is clear
that there were no any predictable overall winners. The correlation
between winning multiple “Star Baker” titles and winning the “Series
Winner” is not consistent. What stands out the most is that
multiple_time “Star Bakers” do not always end up with winning the
series, which goes against what many people might expect. This makes the
outcome of each series more surprising and unpredictable.

## Section 5: Dataset exploration of viewers.csv

``` r
viewers_df =
  read_csv("data/gbb_datasets/viewers.csv", na = c("NA", "", ".", " ")) |> 
  janitor::clean_names()
```

The first 10 rows of this dataset:

``` r
head(viewers_df,10)
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

``` r
Ave_viewership1 = mean(pull(viewers_df,series_1), na.rm = TRUE)
  
Ave_viewership5 = mean(pull(viewers_df,series_5))
```

By checking the original imported dataset, I found there are missing
values (NAs) for series_1 whereas series_5 contains no missing value.

The average viewership for Season 1 was 2.77, and for Season 5 was
10.0393.
