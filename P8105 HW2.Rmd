---
title: "P8105 Homework 2"
output: github_document
---
Name: Xi Peng   UNI: xp2213    Date: 10.02.2024

```{r setup, echo=FALSE, message=FALSE}
library(tidyverse)
library(readxl)
library(haven)
library(tidyr)
library(dplyr)
```


# Problem 1 NYC Transit Data

## Section 1: Data Import

```{r, message=FALSE}

NYCtransit_df =
    read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA", "", ".", " ")) |>
  janitor::clean_names() |> 
  unite("routes_served", c(route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11), sep = ",", remove = TRUE, na.rm = TRUE) |> 
  select(line, station_name, station_latitude, station_longitude, routes_served, entry, vending, entrance_type, ada) |>  mutate(
    entry = case_match(
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE
    )
  ) |> 
  relocate(line, station_name, station_latitude, station_longitude, routes_served, entry, vending, entrance_type, ada)

```

The NYC Transit Subway Entrance and Exit dataset contains information about different subway station's entrances and exits. Other detailed information, such as which subway lines stop at which station and their geographic coordinates, ADA compliance, and detailed information about the entrances, staffing status, etc.In this step, I cleaned the dataset by only keep the required variables: `r names(NYCtransit_df)`. The variable "entry" also converted to `r class(pull(NYCtransit_df,entry))`. After the cleaning step, the tidy dataset contains `r nrow(NYCtransit_df)` rows and `r ncol(NYCtransit_df)` columns.


## Section 2
```{r}

distinct_station =
  NYCtransit_df |> distinct(station_name,line)

ADA_compliant_station =
  NYCtransit_df |> 
  filter(ada == TRUE) |> 
  distinct(station_name,line)

Entry_without_vending = 
  NYCtransit_df |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()

```

In this dataset, there are `r nrow(distinct_station)` distinct stations and `r nrow(ADA_compliant_station)` stations are ADA compliant. The proportion of station entrances / exits without vending allow entrance is `r Entry_without_vending`.


## Section 3
```{r}

station_served_A = NYCtransit_df |> 
  filter(grepl("A", routes_served)) |> 
  distinct(station_name, line) |> 
  nrow()
  
ADA_compliant_A = NYCtransit_df |> 
  filter(grepl("A", routes_served), ada == TRUE) |> 
  distinct(station_name,line) |> 
  nrow()

```

There are `r station_served_A` distinct stations serve the A train and `r ADA_compliant_A` of the stations that serve the A train are ADA compliant.



# Problem 2 Trash Wheel Dataset

## Section 1: Data Import & Cleaning of the "Mr. Trash Wheel" Sheet

```{r}

Mr_wheel = 
  read_excel("Data/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", 
  col_types = c("numeric","text","text","date","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","skip","skip"), skip = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    sports_balls = as.integer(round(sports_balls))
  )

```

In section 1, the original dataset was imported, and the "Mr. Trash Wheel" sheet was selected. After examining the content of the original excel dataset, I identified columns labeled "x15" and "x16" as non-data columns containing only NAs. Therefore, these two columns were removed. The first row, which contained figure but not actual data, was removed. Additionally, any rows that did not correspond to a specific dumpster were filtered out from the dataset. Lastly, the values in the "sports_balls" column were rounded to nearest integer and converted to integer variable.


## Section 2: Cleaning of the "Professor Trash Wheel" Sheet and "Gwynnda Trash Wheel" Sheet

```{r}

Prof_wheel = 
  read_excel("Data/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) 

Gwynnda_wheel = 
  read_excel("Data/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel") |> 
  janitor::clean_names() |> 
  drop_na(dumpster)

```

In section 2, similar steps were taken to clean the "Professor Trash Wheel" sheet and "Gwynnda Trash Wheel" sheet. After importing the original datasets of these two sheets, their contents were examined to ensure that no non-data entries were present. Also, any rows that did not correspond to a specific dumpster were filtered out from the datasets.

In all three datasets, columns that are not considered non-data but contain many NA values are kept. Similarly, rows that lack useful information are also retained as long as they include dumpster-specific data.


## Section 3: Combination of "Mr. Trash Wheel", "Professor Trash Wheel", and "Gwynnda Trash Wheel" sheets

```{r}

Mr_wheel_com = Mr_wheel |> mutate(trash_wheel_device = "Mr.", year = as.numeric(year))
Prof_wheel_com = Prof_wheel |> mutate(trash_wheel_device = "Professor")
Gwynnda_wheel_com = Gwynnda_wheel |> mutate(trash_wheel_device = "Gwynnda")

trash_wheel_df = 
  bind_rows(Mr_wheel_com, Prof_wheel_com, Gwynnda_wheel_com) |> 
  janitor::clean_names() |> 
  relocate(trash_wheel_device)

total_weight_trash_Prof = trash_wheel_df |> 
  filter(trash_wheel_device == "Professor") |> 
  drop_na(weight_tons) |> 
  pull(weight_tons) |> 
  sum()

total_cigarette_Gwynnda = trash_wheel_df |> 
  filter(trash_wheel_device == "Gwynnda", month == "June", year == 2022 ) |> 
  drop_na(cigarette_butts) |> 
  pull(cigarette_butts) |> 
  sum()

```

In section 3, the three sheets were combined. The combined dataset contains a total of `r nrow(trash_wheel_df)` observations and `r ncol(trash_wheel_df)` columns. The variables included in this dataset are: `r names(trash_wheel_df)`. An additional column,"trash_wheel_device", was created based on the Trash Wheel Website introduction to denote which specific trash wheel device each observation belongs to. Among these varaibles, both the "dumpster" variable, which represents the dumpster number, and the "trash_wheel_device" variable are essential indicators provide timely and effective access to critical and detailed information for each observation. Therefore, I relocated the "trash_wheel_device" to a forward position, specifically to the first column in the dataset, to facilitate easier information extraction.Based on provided data, the total weight of trash collected by Professor Trash Wheel was `r total_weight_trash_Prof` tons, and the total number of cigarette butts collected by Gwynnda in June of 2022 was `r total_cigarette_Gwynnda`.



# Problem 3 Great British Bake Off Dataset

## Section 1: Data import and Creation of a single, well-organized dataset

```{r, message=FALSE}

bakers_df =
  read_csv("data/gbb_datasets/bakers.csv", na = c("NA", "", ".", " ")) |> 
  janitor::clean_names() |> 
  mutate(
    baker_first_name = word(baker_name, 1),
    baker_last_name = word(baker_name, -1)
  ) |> 
  select(-baker_name)

bakes_df =
  read_csv("data/gbb_datasets/bakes.csv", na = c("NA", "", ".", " ")) |> 
  janitor::clean_names() |> 
  rename(baker_first_name = baker)

results_df =
  read_csv("data/gbb_datasets/results.csv", na = c("NA", "", ".", " "), skip = 2) |> 
  janitor::clean_names() |> 
  rename(baker_first_name = baker) |> 
  mutate(
    result = case_match(
      result,
      "IN" ~ "stayed in",
      "OUT" ~ "Eliminated", 
      "STAR BAKER" ~ "Star Baker",
      "WINNER" ~ "Series Winner",
      "Runner-up" ~ "Series Runner up",
      "WD" ~ "withdrew"
    )
  )

```

In this section, the datasets were imported, and I reviewed the contents of each dataset. I noticed that the bakers' names in the baker.csv file were full names, whereas the other datasets only contained the bakers' first names. To ensure consistency across the datasets, I split the full names in baker.csv into separate columns as baker_first_name and baker_last_names. After verifying the consistency between the first_name and last_name columns and the original baker_name colomn, I removed the baker_name variable to avoid redundant information. I then labeled the baker as baker_first_name in all datasets, ensuring consistency. Additionally, in the results.csv dataset, the first two rows contains non-data values, so they have been removed.The values of result column in the results.csv were converted into more descriptive phrases, which is useful for readability and interpretation.

## Section 2: Check for completeness and correctness across datasets.

```{r}
anti_join(bakers_df,bakes_df)

anti_join(bakers_df,results_df)

anti_join(results_df,bakes_df)
```

## Section 3: Combining and organizing data into a meaningful structure

```{r}

GBbakeoff_df = results_df |> 
  left_join(bakes_df, by = c("series","baker_first_name","episode")) |> 
  left_join(bakers_df, by = c("baker_first_name","series")) |> 
  relocate(series, episode, baker_first_name, baker_last_name, baker_age, baker_occupation, hometown, technical, result,signature_bake, show_stopper)
  
```

Exporting the final dataset as a CSV:

```{r}

write_csv(GBbakeoff_df,"data/GBbakeoff_df.csv")

```

## Section 4: Table Creation

```{r}

Star_win_df = 
  GBbakeoff_df |> 
  filter(series>=5 & series<=10, result == c("Star Baker","Series Winner")) |> 
  select(series, episode, baker_first_name, baker_last_name, baker_age, result, baker_occupation, hometown, technical,signature_bake, show_stopper)

knitr::kable(
  Star_win_df,format = "html",
  caption = "Table of Star baker/Winner of each episode in Seasons 5 through 10 "
  )



```

In this section, the question asks about the star baker/winner of each episode in Seasons 5 through 10. I filtered out these persons and formed a reader-friendly table. The key information, such as the which series and episode the star baker/winner attend and results for illustrating they were either star baker or winner, were placed in front. Other personally relevant information of each participant was placed afterwards. 

According to the table, the first thing I noticed is that Richard Burr earned "Star Baker" title in four episodes of Series 5. However, Nancy Birtwhistle was the "Series Winner" for that series. Similarly, in Series 6, Ian Cumming won "Star Backer" in two episodes, and Candice Brown did the same in Series 7. In Series 9, there were five different "Star Bakers" which is one more than in the other series. In Series 10, Steph Balckwell earned two "Star baker" title in two episodes, yet David Atherton was the "Series winner". Interestingly, there is no "Series Winner" recored for Series 6, 7, 8, and 9.In conclusion, based on the patterns observed in this table, it is clear that there were no any predictable overall winners. What stands out the most is that multiple_time "Star Bakers" do not always end up with winning the series, which goes againt what many people might expect. This makes the outcome of each series more surprising and unpredictable.

